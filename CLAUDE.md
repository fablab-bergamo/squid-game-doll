# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

A "Red Light, Green Light" robot inspired by Squid Game TV series, using AI for player recognition and tracking with an animated doll and optional laser targeting system. Players register via face detection, move during green light phases, and are eliminated if they move during red light phases. The system runs on either PC (with CUDA support recommended) or Raspberry Pi 5 with Hailo AI KIT.

## Development Commands

### Setup and Installation
```bash
# Install poetry and dependencies
pip install poetry
poetry install

# For CUDA support on PC (optional)
poetry run pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --force-reinstall

# For Raspberry Pi with Hailo support
poetry install
poetry run pip install git+https://github.com/hailo-ai/hailo-apps-infra.git

# Download Hailo models for Raspberry Pi
wget https://hailo-model-zoo.s3.eu-west-2.amazonaws.com/ModelZoo/Compiled/v2.14.0/hailo8l/yolov11m.hef
```

### ESP32 Development
```bash
# ESP32 files are located in esp32/ folder
# Use Thonny IDE (https://thonny.org/) for MicroPython development
# Flash MicroPython firmware to ESP32C2 MINI Wemos board

# Main files:
# - boot.py: WiFi connection and auto-start
# - tracker.py: Main control server for doll and laser systems  
# - Servo.py: Custom servo control class for SG90 motors
```

### Running the Application
```bash
# Configure vision areas (generates config.yaml)
poetry run python -m src.squid_game_doll.run --setup

# Run with default configuration
poetry run python -m src.squid_game_doll.run

# Run with specific hardware configuration
poetry run python -m src.squid_game_doll.run -m 0 -w 0 -k -i 192.168.45.50

# All CLI options:
# -m/--monitor: 0-based monitor index
# -w/--webcam: 0-based webcam index  
# -k/--killer: enable ESP32 laser shooter
# -i/--tracker-ip: ESP32 IP address (default: 192.168.45.50)
# -j/--joystick: joystick index
# -n/--neural_net: custom neural network model file
# -c/--config: config file (default: config.yaml)
# -s/--setup: setup mode for area configuration
```

### Testing and Quality
```bash
# Run tests
poetry run pytest

# Code formatting and linting (development dependencies)
poetry install --with dev
poetry run black .
poetry run flake8 .

# Performance profiling
poetry run python -m cProfile -o game.prof -m src.squid_game_doll.run
poetry run snakeviz ./game.prof
```

## Architecture Overview

### Core Game Components
- **SquidGame**: Main game controller managing state transitions (LOADING → INIT → GREEN_LIGHT → RED_LIGHT → VICTORY/GAMEOVER)
- **GameScreen**: Pygame-based rendering engine for UI and game display
- **GameCamera**: Webcam interface with frame processing and coordinate transformations
- **GameSettings**: Configuration management for vision areas, game parameters, and hardware settings

### Player Detection and Tracking
- **BasePlayerTracker**: Abstract base for player detection systems
- **PlayerTrackerUL**: Ultralytics YOLO implementation for PC (supports CUDA)
- **PlayerTrackerHailo**: Hailo AI accelerated tracking for Raspberry Pi 5
- **Player**: Player state management (position, face, elimination status, movement detection)
- **FaceExtractor**: Mediapipe-based face detection for player registration

### Laser Targeting System (Work in Progress)
- **LaserShooter**: ESP32 communication for servo control and laser activation
- **LaserTracker**: Computer vision laser dot detection and positioning feedback  
- **LaserFinder**: Image processing pipeline for laser dot recognition using threshold + dilate + Hough circles
- **Status**: Currently under development, basic targeting implemented but requires refinement

### Configuration and Setup
- **ConfigPhase**: Interactive setup for defining vision areas (start zone, finish zone, play area)
- **Calibrator**: Camera calibration utilities

## Platform-Specific Behavior

### Neural Network Model Selection
- **Linux (Raspberry Pi)**: Automatically uses Hailo models (.hef files) via PlayerTrackerHailo
- **Windows/PC**: Uses Ultralytics YOLO models via PlayerTrackerUL
- Models are loaded dynamically based on platform detection

### Hardware Integration
- **ESP32 Controller**: MicroPython-based servo and LED control (see esp32/ folder)
- **Webcam**: Logitech C920 recommended, manual exposure control for laser detection
- **Laser System**: Optional pan-tilt platform with red/green laser (work in progress, safety considerations noted)

## Key Configuration Files

- **config.yaml**: Generated by setup mode, contains vision areas and game parameters
- **pyproject.toml**: Poetry dependencies and project metadata
- **run.sh**: Example launch script for Raspberry Pi deployment

## Game Flow and States

1. **LOADING**: Intro screen while neural network models load
2. **INIT**: 15-second player registration phase (face capture in start area)
3. **GREEN_LIGHT**: Players can move toward finish line
4. **RED_LIGHT**: Motion detection active, violators eliminated
5. **VICTORY/GAMEOVER**: End state based on player outcomes

## Testing Strategy

Tests focus on core game logic components:
- GameSettings serialization/deserialization
- Player state management and movement detection
- Configuration file handling
- Basic component initialization

The test suite uses pytest with pygame initialization fixtures and does not test hardware-dependent components (camera, ESP32, neural networks).

## ESP32 Hardware Controller

### Architecture
The ESP32 controller manages physical doll components via a TCP server (port 15555) that receives commands from the main Python application.

### Hardware Connections (ESP32C2 MINI Wemos)
```
GPIO Pin | Component        | Function
---------|------------------|------------------
Pin 3    | SG90 Servo       | Head rotation (0-180°)
Pin 1    | PWM LEDs         | Eyes brightness control
Pin 5    | SG90 Servo       | Laser H-axis (pan) - WIP
Pin 4    | SG90 Servo       | Laser V-axis (tilt) - WIP  
Pin 2    | Laser Module     | Laser on/off - WIP
Pin 7    | RGB LED          | Status indicator (built-in)
```

### Key ESP32 Files
- **boot.py**: Auto-connects to WiFi, sets hostname, imports tracker module
- **tracker.py**: Main async server handling doll control and laser targeting
- **Servo.py**: Custom servo control class optimized for SG90 motors

### Communication Protocol
The ESP32 exposes these commands via TCP:
```python
# Doll control
"h0"           # Head position 0 (facing forward)
"h1"           # Head position 180 (turned away) 
"e0"           # Eyes off
"e1"           # Eyes on (pulsing effect)

# Laser targeting (Work in Progress)
"(h_angle, v_angle)"  # Set laser target coordinates
"on"/"off"     # Laser enable/disable
"angles"       # Get current servo positions
"limits"       # Get servo angle limits

# Utility
"test"         # Start servo test movement
"stop"         # Stop test movement
"quit"         # Close connection
```

### ESP32 Development Workflow
1. Install MicroPython firmware on ESP32C2 MINI
2. Use Thonny IDE for code development and upload
3. Configure WiFi credentials in boot.py (replace "SSID"/"Password")
4. Upload all three files to ESP32 root directory
5. ESP32 will auto-start server on boot at IP shown in serial output

### Important ESP32 Notes
- WiFi hostname set to "esp32tracker" for easy network identification
- Server automatically restarts if client disconnections occur
- Servo movements are smoothed to prevent jerky motion
- Built-in RGB LED indicates WiFi connection status (green=connected, red=disconnected)
- Head positioning uses gradual movement for realistic doll animation
- Eyes use PWM for smooth pulsing effect during red light phases

## Development Notes

- Webcam exposure must be manually controlled for reliable laser detection
- Frame rate typically 10 FPS for game loop, 30 FPS possible with CUDA acceleration
- Vision areas must be properly configured for game mechanics to work
- Face detection runs on CPU and can be performance bottleneck
- Laser targeting requires careful calibration of threshold parameters (Work in Progress)
- ESP32 communication uses simple TCP protocol for reliability
- Servo angle limits are configurable in tracker.py constants